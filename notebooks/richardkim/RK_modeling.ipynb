{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import random as rn\n",
    "import sklearn\n",
    "# from scipy import stats\n",
    "# import math\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import  LabelEncoder #OneHotEncoder\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,accuracy_score\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "totDF = pd.read_csv('../../data/processed/Cleaned_Data_Set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning / Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = re.compile('.*reporting')\n",
    "r2 = re.compile('.*imputed')\n",
    "\n",
    "cols_to_drop1 = list(filter((r1.match), totDF.columns))\n",
    "cols_to_drop2 = list(filter((r2.match), totDF.columns))\n",
    "cols_to_drop3 = ['admit_NICU']\n",
    "cols_to_drop = cols_to_drop1 + cols_to_drop2 + cols_to_drop3\n",
    "\n",
    "cols_to_keep = [col for col in totDF.columns if col not in cols_to_drop]\n",
    "\n",
    "X_and_target = totDF[cols_to_keep + ['admit_NICU']].copy()\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "catDF = X_and_target.select_dtypes(include=object).copy()\n",
    "numDF = X_and_target.select_dtypes(include=numerics).copy() #only numeric columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "catDF = catDF.apply(le.fit_transform)\n",
    "\n",
    "concat_df = pd.concat([numDF,catDF],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size : 500\n",
      "\n",
      "CPU times: user 46.1 ms, sys: 3 ms, total: 49.1 ms\n",
      "Wall time: 49.7 ms\n",
      "sample size: 500 \n",
      "score      : 0.946\n",
      "--------------------------------------------------\n",
      "sample size : 5000\n",
      "\n",
      "CPU times: user 607 ms, sys: 61.2 ms, total: 668 ms\n",
      "Wall time: 176 ms\n",
      "sample size: 5000 \n",
      "score      : 0.9208\n",
      "--------------------------------------------------\n",
      "sample size : 10000\n",
      "\n",
      "CPU times: user 1.21 s, sys: 134 ms, total: 1.34 s\n",
      "Wall time: 357 ms\n",
      "sample size: 10000 \n",
      "score      : 0.9238\n",
      "--------------------------------------------------\n",
      "sample size : 25000\n",
      "\n",
      "CPU times: user 2.91 s, sys: 282 ms, total: 3.19 s\n",
      "Wall time: 842 ms\n",
      "sample size: 25000 \n",
      "score      : 0.92116\n",
      "--------------------------------------------------\n",
      "sample size : 50000\n",
      "\n",
      "CPU times: user 5.86 s, sys: 532 ms, total: 6.39 s\n",
      "Wall time: 1.69 s\n",
      "sample size: 50000 \n",
      "score      : 0.9245\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sample_per_year in [100, 1000, 2000, 5000, 10000]:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    logit_1 = linear_model.LogisticRegression(solver = 'lbfgs', multi_class='auto')\n",
    "    logit_1.set_params(C=1e4)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time logit_1.fit(cl_df, encoded_target)\n",
    "    print('sample size: {0} \\nscore      : {1}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 712 ms, sys: 82.4 ms, total: 795 ms\n",
      "Wall time: 3.99 s\n",
      "Random Forest\n",
      "sample size: 500\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 12}\n",
      "best score : 0.918\n",
      "r2         : 0.3360049829006593\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 477 ms, sys: 21.1 ms, total: 498 ms\n",
      "Wall time: 2.64 s\n",
      "Random Forest\n",
      "sample size: 1000\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 21}\n",
      "best score : 0.925\n",
      "r2         : 0.3434557735753849\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 677 ms, sys: 26.4 ms, total: 704 ms\n",
      "Wall time: 6.4 s\n",
      "Random Forest\n",
      "sample size: 2500\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 27}\n",
      "best score : 0.942\n",
      "r2         : 0.404304039263532\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 2.05 s, sys: 139 ms, total: 2.19 s\n",
      "Wall time: 16.8 s\n",
      "Random Forest\n",
      "sample size: 5000\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 50}\n",
      "best score : 0.9434\n",
      "r2         : 0.41487286337463625\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 2.6 s, sys: 144 ms, total: 2.75 s\n",
      "Wall time: 50.5 s\n",
      "Random Forest\n",
      "sample size: 10000\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 30}\n",
      "best score : 0.9457\n",
      "r2         : 0.443801211132967\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 5.88 s, sys: 421 ms, total: 6.31 s\n",
      "Wall time: 4min 7s\n",
      "Random Forest\n",
      "sample size: 25000\n",
      "best param : {'min_samples_leaf': 10, 'n_estimators': 92}\n",
      "best score : 0.94588\n",
      "r2         : 0.4496835070860762\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sample_per_year in [100, 200, 500, 1000, 2000, 5000]:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    randomForest = ensemble.RandomForestClassifier(random_state = 108, warm_start = True)\n",
    "    grid_para_forest = [{\n",
    "        \n",
    "        # fix the numbers as sample size increases\n",
    "#         'n_estimators' : range(1000,10000,1000),\n",
    "        'n_estimators' : np.linspace(10,int(np.sqrt(len(cl_df))),10,dtype=int),\n",
    "#         'min_samples_split' : [100,10,2],\n",
    "        'min_samples_leaf' : range(10,100,10)\n",
    "        \n",
    "    }]\n",
    "    randomForest.set_params(random_state=108)\n",
    "    grid_search_forest = GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    %time grid_search_forest.fit(cl_df, encoded_target) #put in the df here\n",
    "    print(\n",
    "    '''Random Forest\n",
    "sample size: {0}\n",
    "best param : {1}\n",
    "best score : {2}\n",
    "r2         : {3}'''\\\n",
    "      .format(len(encoded_target), \\\n",
    "              grid_search_forest.best_params_,\\\n",
    "              grid_search_forest.best_score_, \\\n",
    "              r2_score(encoded_target, grid_search_forest.predict(cl_df)))\n",
    "     )\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
