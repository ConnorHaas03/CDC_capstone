{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totDF = pd.read_csv('../data/raw/Cleaned_data_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for cleaning and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the df and encode numeric values\n",
    "def cleanDF (df):\n",
    "    r1 = re.compile('.*reporting')\n",
    "    r2 = re.compile('.*imputed')\n",
    "\n",
    "    cols_to_drop1 = list(filter((r1.match), df.columns))\n",
    "    cols_to_drop2 = list(filter((r2.match), df.columns))\n",
    "    cols_to_drop3 = ['admit_NICU']\n",
    "    cols_to_drop = cols_to_drop1 + cols_to_drop2 + cols_to_drop3\n",
    "\n",
    "    cols_to_keep = [col for col in df.columns if col not in cols_to_drop]\n",
    "\n",
    "    X_and_target = df[cols_to_keep + ['admit_NICU']].copy()\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    catDF = X_and_target.select_dtypes(include=object).copy()\n",
    "    numDF = X_and_target.select_dtypes(include=numerics).copy() #only numeric columns\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    catDF = catDF.apply(le.fit_transform)\n",
    "\n",
    "    concat_df = pd.concat([numDF,catDF],axis=1)\n",
    "    return concat_df\n",
    "\n",
    "def gsForest(X,Y):\n",
    "    randomForest = ensemble.RandomForestClassifier()\n",
    "    grid_para_forest = [{\n",
    "        'n_estimators': np.linspace(50,int(np.sqrt(len(cl_df))),10,dtype=int),\n",
    "        'min_samples_leaf' : range(100,1000,100)\n",
    "    }]\n",
    "    randomForest.set_params(random_state=108)\n",
    "    gs_forest = GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', \n",
    "                                      cv=5, n_jobs=-1)\n",
    "    %time gs_forest.fit(X, Y)\n",
    "    return gs_forest\n",
    "\n",
    "def RF (X,Y,gs):\n",
    "    bestRF = ensemble.RandomForestClassifier()\n",
    "    best_params = gs.best_params_\n",
    "    bestRF.set_params(random_state=108,n_jobs= -1,oob_score = True,**best_params)\n",
    "    bestRF.fit(X,Y)\n",
    "    return bestRF\n",
    "\n",
    "def pred_results(fullDF, gsf, rf):\n",
    "    X_bal = fullDF.drop('admit_NICU',axis=1)\n",
    "    y_pred = rf.predict(X_bal)\n",
    "\n",
    "    #Use sklearn's confusion_matrix on real and predicted y\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(fullDF.admit_NICU, y_pred))\n",
    "\n",
    "    print(\n",
    "        '''Random Forest\n",
    "    best param : {0}\n",
    "    best score : {1}\n",
    "    r2         : {2}'''\\\n",
    "          .format(gsf.best_params_,\\\n",
    "                  gsf.best_score_, \\\n",
    "                  r2_score(fullDF.admit_NICU, y_pred))\n",
    "         )\n",
    "    return\n",
    "\n",
    "def feature_select(X,rf):\n",
    "    sampRF_coefs = pd.DataFrame({'col' :list(X.columns), \n",
    "                           'features': rf.feature_importances_})\n",
    "    return sampRF_coefs.nlargest(10,'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a col of Y and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = cleanDF(totDF)\n",
    "nicu_allY = cl_df.loc[cl_df['admit_NICU']==2]\n",
    "nicu_allN = cl_df.loc[cl_df['admit_NICU']==0]\n",
    "nicu_YN = pd.concat([nicu_allY,nicu_allN],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF on Balanced Sample per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_per_year = 10000\n",
    "bal_dwnSmplY = nicu_allY.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "bal_dwnSmplN = nicu_allN.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "bal_dwnSmpl = pd.concat([bal_dwnSmplY,bal_dwnSmplN],axis=0)\n",
    "\n",
    "bal_target = bal_dwnSmpl.admit_NICU #target\n",
    "bal_X = bal_dwnSmpl.drop('admit_NICU',axis=1) #X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train RF with best params by training a Grid search for hyp param selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_gs = gsForest(bal_X,bal_target)\n",
    "bal_rf = RF(bal_X,bal_target,bal_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_results(nicu_YN,bal_gs,bal_rf)\n",
    "feature_select(bal_X,bal_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_100k = '../data/processed/bal100K_model.sav'\n",
    "pickle.dump(bal_gs, open(bal_100k, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF on Samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 5000\n",
    "sampN = nicu_allN.sample(sample)\n",
    "sampY = nicu_allY.sample(sample)\n",
    "samp = pd.concat([sampN,sampY],axis=0)\n",
    "\n",
    "samp_target = samp.admit_NICU\n",
    "samp_X = samp.drop('admit_NICU',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train RF with best params by training a Grid search for hyp param selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_gs = gsForest(samp_X,samp_target)\n",
    "samp_rf = RF(samp_X,samp_target,samp_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal = nicu_YN.drop('admit_NICU',axis=1)\n",
    "y_pred = samp_rf.predict(X_bal)\n",
    "cnf = confusion_matrix(nicu_YN.admit_NICU, y_pred)\n",
    "cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results(nicu_YN,samp_gs,samp_RF) #show conf matrix and results\n",
    "feature_select(samp_X,samp_RF) #top 10 features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
